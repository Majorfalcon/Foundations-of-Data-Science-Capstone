---
title: "Capstone - Machine Learning"
author: "Andre Velez"
output:
  html_document: 
    keep_md: true
---
# __Predicting The Effects Of Unemployment And Education On Violent Crime Rate__

### __Machine Learning__
This project used supervised linear regression machine learning techniques to produce models based upon the insights achieved from the EDA. A linear regression model will be created using statistically significant features to predict the response of VCR. Specifically, the features evaluated are: Unemployment Rate, College Graduation Rate, Median Income, Median Debt, College Retention Rate, and Average Cost of College.  Both the MV and LV data sets have their own models to be used in discovering what the different features/predictors effects are on VCR.  Two methods to determine the best model features used in this project are stepwise multiple linear regression and best subsets multiple linear regression.

The stepwise method begins with all predictors being included in the model, with removal of non-significant factors in a step by step method. This method allows analysis of the beta constants, p values, F statistic, and adjusted R2 for all the features present in the data sets to determine which features are not statistically significant, or potentially have multicollinearity with other features which can lead to an overfitting.  However this method can lead to bias in the selection process by focusing sticking with variables early on to achieve higher adjusted R2 and lower p values, potentially missing more significant feature selection combinations that produce a stronger fitting model to the data in question.

The best subsets regression method was used to address the limitations of the stepwise method. Instead of identifying a single model based on statistical significance, best subsets feature selection exhaustively evaluates a number of different models and statistical values, and displays them in a matrix to help visualize the comparison.

Both methods produce a number of statistical values for the regression models.  Each model's fit and predictive strength was evaluated using the following parameters: R2, Adjusted R2, Predictive R2, and P Value.

R2 (coefficient of determination) is a statistical measure of how close the data are to the fitted regression line.  This value ranges from 0-100% and is the percentage of the response/dependent variable variation (VCR) that is explained by the model.  0% denotes the given model explains none of the variability of VCR around its mean, while 100% denotes the model explains all the variability.  Higher R2 means the model fits the data better; however there are many limitations of this statistic with multiple linear regressions. R2 inherently increases every time a predictor is added to a model, falsely leading to the conclusion that a model with more variables is a better fit to the data and has stronger predictive accuracy.  Having more predictors also leads to the model being subject to overfitting, where it models random noise in the data. Adjusted R2 addresses many of the limitations of R2, and is a more acceptable statistic to use for model selection. R2 also cannot determine bias of the coefficient estimates and predictions; residual plots must be examined to determine bias.

Adjusted R2 is directly proportional to the MSE, and thus can compare the explanatory accuracy of regression models that contain different numbers of predictors. Its value increases only if the new predictor improves the model more than would be expected by chance, and decreases when a predictor improves the model by less than expected by chance. This leads to a better statistic to use when dealing with multiple linear regression models, but still has the limitation of being subject to the sample data.  This limits its predictive accuracy when used on unseen data.

Predicted R2 is directly proportional to the PRESS statistic (predicted residual sum of squares), and can indicate how well a model predicts the responses of new data.  It works by methodically removing each observation in the data set, estimating the regression, and using that estimation to predict the removed observation.  Predicted R2 also prevents overfitting, because it is impossible to predict random noise thus predicted R2 will drop for an overfit model.

P values are used to determine statically significance in hypothesis tests.  Technically, it is the probability of obtaining an effect at least as extreme as the one in your sample data, assuming the truth of the null hypothesis. This means assuming a true null hypothesis (the predictors effects on VCR are by random chance), how likely is the data. A high P value indicates the data agree with a true null, and a low P value indicates the data are unlikely with a true null.  Low P values in this project indicate that the predictors are statistically significant enough to not be a random effect on VCR.

Combining all these variables will allow us to choose the best model containing the most significant features.  This model for both MV and LV data sets will then be tested via k-fold cross-validation, where the original samples is randomly partitioned into k subsamples and one is left out in each iteration.  Cross-validation is another way to measure predictive performance of a statistical model by taking removing a subset of data as a "test set" and evaluating the remaining data as the "training set".  The test set is then introduced as new unseen data to evaluate the predictive accuracy of the training set. The RMSE (root mean squared error) indicates how close the predicted values are from the actual data. RMSE values close in comparison indicate a higher predictive accuracy for the model being validated.
